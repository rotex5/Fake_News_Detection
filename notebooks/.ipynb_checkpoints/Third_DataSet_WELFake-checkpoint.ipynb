{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a359836",
   "metadata": {
    "id": "0a359836"
   },
   "source": [
    "# Fake New Dectection USing Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35269a",
   "metadata": {
    "id": "9a35269a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,string,unicodedata\n",
    "import os\n",
    "\n",
    "# NLP Libs\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#ML Algos\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             matthews_corrcoef,\n",
    "                             cohen_kappa_score,\n",
    "                             roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s_SnXcVuPubj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_SnXcVuPubj",
    "outputId": "6bb47d02-4178-4e86-9e47-a35e586df612"
   },
   "outputs": [],
   "source": [
    "# Import our data\n",
    "\n",
    "df = pd.read_csv(\"./dataset/WELFake_dataset/WELFake_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0d342",
   "metadata": {
    "id": "d6d0d342"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1879e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ca953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the labels: 0 to 1 and 1 to 0\n",
    "df['label'] = 1 - df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d593b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "126d593b",
    "outputId": "028d49b1-4126-4c3f-c295-cfa3042c0327"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931fda9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2931fda9",
    "outputId": "af29f57a-0094-4163-da1a-264bac489447"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3070080",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3070080",
    "outputId": "e8235c21-bcfb-4499-ae11-b7a729fdda48"
   },
   "outputs": [],
   "source": [
    "# Visualization Libs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "#sns.countplot(df.label)\n",
    "sns.countplot(data=df, x='label')\n",
    "\n",
    "plt.title('Total Fake and Real News Articles', fontsize=24)\n",
    "plt.ylabel('Total', fontsize=16)\n",
    "plt.xlabel('')\n",
    "plt.xticks([1, 0], ['Fake', 'Real'], fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29aad1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "f29aad1b",
    "outputId": "3172c7c8-bfa7-4ca5-a848-ccb2230db83a"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3e8c9",
   "metadata": {
    "id": "6cd3e8c9"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1da327",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "7d1da327",
    "outputId": "74637429-47a7-4125-9c65-87fdf8c896db"
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61749b5",
   "metadata": {
    "id": "e61749b5"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51911b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1f51911b",
    "outputId": "b48c0bab-950e-4411-ebcb-2203ba9e5588"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(' ')\n",
    "# Now we'll create the Corpus that will be used in our NLP model\n",
    "\n",
    "# This will create a single column with all the relevant text\n",
    "\n",
    "df['total']=df['title']+' '+df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369608b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'title','text'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8dffe0",
   "metadata": {
    "id": "6b8dffe0"
   },
   "source": [
    "# Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_XGkq6inVqEt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XGkq6inVqEt",
    "outputId": "9f3cf8fb-c5c3-4f2e-d139-2d5a51201817"
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8619ada",
   "metadata": {
    "id": "d8619ada"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "for index,row in df.iterrows():\n",
    "    filter_sentence = ''\n",
    "\n",
    "    sentence = row['total']\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence) #cleaning\n",
    "    words = nltk.word_tokenize(sentence) #tokenization\n",
    "    words = [w.lower() for w in words if not w in stop_words]  #stopwords removal\n",
    "\n",
    "    for word in words:\n",
    "        filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(word)).lower()\n",
    "\n",
    "    df.loc[index,'total'] = filter_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd495f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fcd495f6",
    "outputId": "6b51f14b-a680-47a7-c266-f0b1c160182a"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oqEAyd5pvzLl",
   "metadata": {
    "id": "oqEAyd5pvzLl"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"./dataset/WELFake_dataset/cleaned_dataset_22.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f1cb4",
   "metadata": {
    "id": "023f1cb4"
   },
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507913e",
   "metadata": {
    "id": "0507913e"
   },
   "outputs": [],
   "source": [
    "X_train = df['total']\n",
    "Y_train = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc5921a",
   "metadata": {
    "id": "3dc5921a"
   },
   "outputs": [],
   "source": [
    "#Feature extraction using count vectorization and tfidf.\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(X_train)\n",
    "freq_term_matrix = count_vectorizer.transform(X_train)\n",
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "tf_idf_matrix = tfidf.fit_transform(freq_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7cfb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cde7cfb0",
    "outputId": "5f80bf33-b897-4893-b72a-062379a64edf"
   },
   "outputs": [],
   "source": [
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f803e3d",
   "metadata": {
    "id": "3f803e3d"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d305c",
   "metadata": {
    "id": "ef1d305c"
   },
   "outputs": [],
   "source": [
    "test_counts = count_vectorizer.transform(df['total'].values)\n",
    "test_tfidf = tfidf.transform(test_counts)\n",
    "\n",
    "#split in samples\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(tf_idf_matrix, Y_train, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Sample data (replace this with your dataset)\n",
    "X = tf_idf_matrix  # Features\n",
    "y = Y_train    # Target labels (0 or 1)\n",
    "\n",
    "# Create an instance of StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Perform the split\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# Now, X_train and y_train contain the training data and labels, and X_test and y_test contain the test data and labelss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb81d45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eb81d45",
    "outputId": "bb0d00ab-573e-4b60-a3cc-e94ae7ecd048"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5217704",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5217704",
    "outputId": "d6434262-dfba-4866-d0d4-63380d4c9364"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79803e",
   "metadata": {
    "id": "6c79803e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b10ae",
   "metadata": {
    "id": "336b10ae"
   },
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6706d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "09d6706d",
    "outputId": "31f16a4a-455c-4ef1-9521-776b52eff054"
   },
   "outputs": [],
   "source": [
    "# DEMO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "pred = logreg.predict(X_test)\n",
    "print('Accuracy of Logistic classifier on training set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "print('====================================')\n",
    "print('Model Precison: ', precision_score(y_test, pred))\n",
    "print('Model Recall Score: ', recall_score(y_test, pred))\n",
    "print('Model F1 Score: ', f1_score(y_test, pred))\n",
    "print('Model Accuracy Score: ', accuracy_score(y_test, pred))\n",
    "print('====================================')\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_test, pred))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm\n",
    "ConfusionMatrixDisplay.from_predictions(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13161897",
   "metadata": {
    "id": "13161897"
   },
   "outputs": [],
   "source": [
    "def get_evaluation_result(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    mcc = matthews_corrcoef(y_test, pred)\n",
    "    kappa = cohen_kappa_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    \n",
    "    print('Accuracy of Logistic classifier on training set: {:.2f}'.format(logreg.score(X_train, y_train)))\n",
    "    print('Accuracy of Logistic classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "    print('====================================')\n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Matthews Correlation Coefficient: {mcc}\")\n",
    "    print(f\"Cohen's Kappa: {kappa}\")\n",
    "    print(f\"AUC-ROC: {roc_auc}\")\n",
    "    print('====================================')\n",
    "    print('classification_report: ')\n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    cm\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773aae5",
   "metadata": {
    "id": "8773aae5"
   },
   "source": [
    "# 1. “lbfgs” Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e178e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "b7e178e4",
    "outputId": "94a4ab3c-5866-4f26-c9f6-d05bb7c88596"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lbfgs = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "get_evaluation_result(lbfgs, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae5007",
   "metadata": {
    "id": "87ae5007"
   },
   "source": [
    "# 2. “liblinear” Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b1055d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "18b1055d",
    "outputId": "46f7189c-a788-49a8-cda5-692fbf0cf16c"
   },
   "outputs": [],
   "source": [
    "liblinear = LogisticRegression(solver='liblinear')\n",
    "\n",
    "get_evaluation_result(liblinear, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfab38a",
   "metadata": {
    "id": "3cfab38a"
   },
   "source": [
    "# 3. “newton-cg” Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c047e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "a73c047e",
    "outputId": "db4f9e20-26a0-46c7-d30b-93b94ffdacdc"
   },
   "outputs": [],
   "source": [
    "newton_cg = LogisticRegression(solver='newton-cg')\n",
    "\n",
    "get_evaluation_result(newton_cg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e68ec1",
   "metadata": {
    "id": "c9e68ec1"
   },
   "source": [
    "# 4. “sag” Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2acbda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "0b2acbda",
    "outputId": "2e222e56-f955-45a2-e047-f376b41481d9"
   },
   "outputs": [],
   "source": [
    "sag = LogisticRegression(solver='sag')\n",
    "\n",
    "get_evaluation_result(sag, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986cf16",
   "metadata": {
    "id": "04a09cf2"
   },
   "source": [
    "# 5. Random Forest Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MwVSTMH9d6se",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "MwVSTMH9d6se",
    "outputId": "36fd9b4d-301e-473d-a6c5-5b9264745a36"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "get_evaluation_result(rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a03527f",
   "metadata": {
    "id": "wWHzclmyfIsV"
   },
   "source": [
    "# 6. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VclTd9n6fXDe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "VclTd9n6fXDe",
    "outputId": "03d5f2f0-3e8a-406c-877f-3b607f39d9fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(max_iter=1000, eta0=0.1, random_state=0)\n",
    "get_evaluation_result(perceptron, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff3d54",
   "metadata": {
    "id": "9JNEVCy-jVU8"
   },
   "source": [
    "# 7. RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9B76yBKQjmy2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "9B76yBKQjmy2",
    "outputId": "6fae38e6-023f-49ee-dad1-123aaa895741"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_classifier = RidgeClassifier(alpha=1.0, solver='auto', random_state=0)\n",
    "get_evaluation_result(ridge_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a4160",
   "metadata": {
    "id": "WF_r799vkXJv"
   },
   "source": [
    "# 8. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nFPdkOSbkX7B",
   "metadata": {
    "id": "nFPdkOSbkX7B"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "# Create a CatBoostClassifier instance with specified hyperparameters\n",
    "catboost_classifier = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, loss_function='Logloss', verbose=0)\n",
    "\n",
    "get_evaluation_result(catboost_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512cdee",
   "metadata": {
    "id": "iOJnIlzNmoR9"
   },
   "source": [
    "# 9. NearestCentroidClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8OIfAH31mpU0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "8OIfAH31mpU0",
    "outputId": "243dc2d7-6d45-4285-ea6c-481ab3b7960b"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "ncc = NearestCentroid()\n",
    "\n",
    "get_evaluation_result(ncc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0594b",
   "metadata": {
    "id": "l-JG5spxnM_E"
   },
   "source": [
    "# 10. Stochastic Gradient Descent (SGDClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8PaGO0f-nNfF",
   "metadata": {
    "id": "8PaGO0f-nNfF"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_classifier = SGDClassifier()\n",
    "\n",
    "get_evaluation_result(sgd_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8b34a",
   "metadata": {
    "id": "rrVv8HVroX3g"
   },
   "source": [
    "# 11. SVC (kernel=”linear”, C=0.025):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HcTLd1iloYY0",
   "metadata": {
    "id": "HcTLd1iloYY0"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_lin = SVC(kernel=\"linear\", C=0.025)\n",
    "\n",
    "get_evaluation_result(svm_lin, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f05aae",
   "metadata": {
    "id": "_xnALbhloZNs"
   },
   "source": [
    "# 12. SVC (gama=2, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oA-hVoEioZgz",
   "metadata": {
    "id": "oA-hVoEioZgz"
   },
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel=\"rbf\", gamma=2, C=1)\n",
    "\n",
    "get_evaluation_result(svm_rbf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d93a74",
   "metadata": {
    "id": "RjrSVVUnqNz5"
   },
   "source": [
    "# 13. LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hb2Hq2roqOF9",
   "metadata": {
    "id": "hb2Hq2roqOF9"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm_classifier = LinearSVC(C=1.0, random_state=0)\n",
    "\n",
    "get_evaluation_result(linear_svm_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af369f0",
   "metadata": {
    "id": "906I7E-lqOWc"
   },
   "source": [
    "# 14. SDGClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V2wocNkuqOxM",
   "metadata": {
    "id": "V2wocNkuqOxM"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# Create an SGDClassifier instance with hinge loss (SVM-like behavior), L2 regularization, and an initial learning rate (eta0)\n",
    "sgd_classifier = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, eta0=0.01, random_state=0, max_iter=1000)\n",
    "\n",
    "get_evaluation_result(sgd_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e201853",
   "metadata": {
    "id": "ay8DRw3oqPFr"
   },
   "source": [
    "# 15. ZeroRGaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_-pQ_gxnreQL",
   "metadata": {
    "id": "_-pQ_gxnreQL"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create a ZeroR classifier\n",
    "zeror_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "get_evaluation_result(zeror_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a05f50",
   "metadata": {
    "id": "wbrCtAY3reKs"
   },
   "source": [
    "# 16. DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7Lb9y2vXreGS",
   "metadata": {
    "id": "7Lb9y2vXreGS"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0)\n",
    "\n",
    "get_evaluation_result(dt_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac75fac3",
   "metadata": {
    "id": "5WkmJn1grd_E"
   },
   "source": [
    "# 17.Passive Aggressive (PassiveAggressiveClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mNSMEzV0rd6u",
   "metadata": {
    "id": "mNSMEzV0rd6u"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pa_classifier = PassiveAggressiveClassifier(C=1.0, random_state=0, max_iter=1000)\n",
    "\n",
    "get_evaluation_result(pa_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464197e",
   "metadata": {
    "id": "iwm-GZDwrduN"
   },
   "source": [
    "# 18.ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FFLsiPGWrdZM",
   "metadata": {
    "id": "FFLsiPGWrdZM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra_tree_classifier = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "get_evaluation_result(extra_tree_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b154a68a",
   "metadata": {
    "id": "RKHic-XHr4fv"
   },
   "source": [
    "# 19.Random Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3q9h9jRyr4aU",
   "metadata": {
    "id": "3q9h9jRyr4aU"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a base learner (e.g., Decision Tree)\n",
    "base_learner = DecisionTreeClassifier()\n",
    "\n",
    "# Create a BaggingClassifier with Random Patches\n",
    "bagging = BaggingClassifier(base_learner, max_samples=0.8, max_features=0.8, n_estimators=10, random_state=42)\n",
    "\n",
    "get_evaluation_result(bagging, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f5d80",
   "metadata": {
    "id": "jrn6OoCkr4XM"
   },
   "source": [
    "# 20.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9r9nCmwBr4T_",
   "metadata": {
    "id": "9r9nCmwBr4T_"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define individual classifiers\n",
    "classifier1 = DecisionTreeClassifier()\n",
    "classifier2 = SVC(probability=True)  # Use probability=True for soft voting\n",
    "classifier3 = RandomForestClassifier()\n",
    "\n",
    "# Create a VotingClassifier instance with soft voting\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('decision_tree', classifier1),\n",
    "    ('svm', classifier2),\n",
    "    ('random_forest', classifier3)\n",
    "], voting='soft')  # You can also use 'hard' for hard voting\n",
    "\n",
    "get_evaluation_result(voting_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1ae023",
   "metadata": {
    "id": "abV4HlODr4RF"
   },
   "source": [
    "# 21. Stacked_generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fxYfkBKjr4Nl",
   "metadata": {
    "id": "fxYfkBKjr4Nl"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=0)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=0))\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create a StackingClassifier instance\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "get_evaluation_result(stacked_model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962f318",
   "metadata": {
    "id": "Vw9ZYa5Rr4KM"
   },
   "source": [
    "# 22.MLPClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ljzJY7Edr3-F",
   "metadata": {
    "id": "ljzJY7Edr3-F"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLPClassifier instance with specified architecture and hyperparameters\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', max_iter=1000, random_state=0)\n",
    "\n",
    "get_evaluation_result(mlp_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z0wjY6lP-aLD",
   "metadata": {
    "id": "z0wjY6lP-aLD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d14505",
   "metadata": {
    "id": "6cyhEvBZ-aHg"
   },
   "source": [
    "# 23.BernoulliRBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ui025zgL-aDL",
   "metadata": {
    "id": "Ui025zgL-aDL"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_classifier = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, learning_rate=0.05, n_estimators=100)\n",
    "\n",
    "get_evaluation_result(lgb_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8126b",
   "metadata": {
    "id": "zHRe_1Ms-Z_9"
   },
   "source": [
    "# 24.AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jj1B9Fw3-Z9A",
   "metadata": {
    "id": "Jj1B9Fw3-Z9A"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=0)\n",
    "\n",
    "get_evaluation_result(adaboost_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb0ef96",
   "metadata": {
    "id": "GYXpzFHM-Z5J"
   },
   "source": [
    "# 25.GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yNqzkZrT-Z1G",
   "metadata": {
    "id": "yNqzkZrT-Z1G"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "get_evaluation_result(gb_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11269a1e",
   "metadata": {
    "id": "-OCzNN6m-Zxa"
   },
   "source": [
    "# 26.Ordinal Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FZShyeqy-Zt1",
   "metadata": {
    "id": "FZShyeqy-Zt1"
   },
   "outputs": [],
   "source": [
    "from mord import LogisticAT\n",
    "\n",
    "# Create and train an Ordinal Logistic Regression model (LogisticAT)\n",
    "ordinal_classifier = LogisticAT(alpha=1.0)  # You can adjust the regularization parameter alpha\n",
    "\n",
    "get_evaluation_result(ordinal_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1740642f",
   "metadata": {
    "id": "-bY97iVN-ZoR"
   },
   "source": [
    "# 27.Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4ac8c",
   "metadata": {
    "id": "xgv03PxR-Zco"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an XGBClassifier instance with specified hyperparameters\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "get_evaluation_result(xgb_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e73fc3",
   "metadata": {
    "id": "I8vjLZBPl-BS"
   },
   "source": [
    "# 28.Decision Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cclYgH_9l9yo",
   "metadata": {
    "id": "cclYgH_9l9yo"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and train a Decision Stump (a DecisionTreeClassifier with max_depth=1)\n",
    "decision_stump = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "get_evaluation_result(decision_stump, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9f0ad",
   "metadata": {
    "id": "1RK0YlAtl_M4"
   },
   "source": [
    "# 29.ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yYg3rgAymgRG",
   "metadata": {
    "id": "yYg3rgAymgRG"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# Create a ComplementNB instance\n",
    "complement_nb_classifier = ComplementNB()\n",
    "get_evaluation_result(complement_nb_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109efaf7",
   "metadata": {
    "id": "OsU87wQ4mfqX"
   },
   "source": [
    "# 30.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lnf2tJDIqPVj",
   "metadata": {
    "id": "Lnf2tJDIqPVj"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a MultinomialNB instance\n",
    "multinomial_nb_classifier = MultinomialNB()\n",
    "get_evaluation_result(multinomial_nb_classifier, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b101e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
